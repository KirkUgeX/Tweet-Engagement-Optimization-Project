{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KirkUgeX/Tweet-Engagement-Optimization-Project/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNqndARkgUd2"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjN2qMSyor_5"
      },
      "outputs": [],
      "source": [
        "path = kagglehub.dataset_download(\"thedevastator/tweets-and-user-engagement\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "csv_file = None\n",
        "for root, dirs, files in os.walk(path):\n",
        "    for file in files:\n",
        "        if file.endswith('.csv') and 'Twitterdatainsheets' in file:\n",
        "            csv_file = os.path.join(root, file)\n",
        "            print(f\"Found CSV file at: {csv_file}\")\n",
        "            break\n",
        "\n",
        "if csv_file:\n",
        "    tweets_df = pd.read_csv(csv_file)\n",
        "    print(f\"Loaded dataset with {len(tweets_df)} tweets\")\n",
        "    print(\"\\nDataset columns:\")\n",
        "    print(tweets_df.columns.tolist())\n",
        "    print(\"\\nSample data:\")\n",
        "    print(tweets_df.head(3))\n",
        "else:\n",
        "    print(\"Could not find the dataset CSV file\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbzDlL4nnNUh"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/kaggle/input/tweets-and-user-engagement/Twitterdatainsheets.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fji2uS92nQLH"
      },
      "outputs": [],
      "source": [
        "df.columns = df.columns.str.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAi1ZkIfnR0p"
      },
      "outputs": [],
      "source": [
        "df = df.iloc[:99998]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6vP5M5mnTXL"
      },
      "outputs": [],
      "source": [
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IcIUxtJnWPA"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
        "    text = re.sub(r\"@\\w+\", '', text)\n",
        "    text = re.sub(r\"[^a-z\\s#]\", '', text)\n",
        "    text = re.sub(r\"\\s+\", ' ', text).strip()\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "def extract_text_features(df):\n",
        "    df = df.copy()\n",
        "    df['text_clean'] = df['text'].apply(clean_text)\n",
        "\n",
        "    df['word_count'] = df['text'].apply(lambda x: len(str(x).split()) if pd.notna(x) else 0)\n",
        "    df['has_question'] = df['text'].str.contains(r'\\?', regex=True, na=False).astype(int)\n",
        "    df['has_exclaim'] = df['text'].str.contains(r'!', regex=True, na=False).astype(int)\n",
        "    df['has_emoji'] = df['text'].str.contains(r'[^\\w\\s#@,.\\-:/]', regex=True, na=False).astype(int)\n",
        "    df['has_hashtag'] = df['text'].str.contains(r'#\\w+', regex=True, na=False).astype(int)\n",
        "    df['has_mention'] = df['text'].str.contains(r'@\\w+', regex=True, na=False).astype(int)\n",
        "\n",
        "    return df\n",
        "def extract_text_features_from_json(data):\n",
        "    if isinstance(data, dict):\n",
        "        data = pd.DataFrame([data])\n",
        "\n",
        "    data['text_clean'] = data['text'].apply(clean_text)\n",
        "\n",
        "    data['word_count'] = data['text'].apply(lambda x: len(str(x).split()) if pd.notna(x) else 0)\n",
        "    data['has_question'] = data['text'].str.contains(r'\\?', regex=True, na=False).astype(int)\n",
        "    data['has_exclaim'] = data['text'].str.contains(r'!', regex=True, na=False).astype(int)\n",
        "    data['has_emoji'] = data['text'].str.contains(r'[^\\w\\s#@,.\\-:/]', regex=True, na=False).astype(int)\n",
        "    data['has_hashtag'] = data['text'].str.contains(r'#\\w+', regex=True, na=False).astype(int)\n",
        "    data['has_mention'] = data['text'].str.contains(r'@\\w+', regex=True, na=False).astype(int)\n",
        "\n",
        "    result_json = data.to_dict(orient=\"records\")\n",
        "    return result_json\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zF7bVGZkvoK3"
      },
      "outputs": [],
      "source": [
        "df = extract_text_features(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_2grfa_nZei"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIWFQiMjnbAG"
      },
      "outputs": [],
      "source": [
        "class TextSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, key): self.key = key\n",
        "    def fit(self, X, y=None): return self\n",
        "    def transform(self, X): return X[self.key]\n",
        "\n",
        "class ColumnDropper(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, text_key): self.text_key = text_key\n",
        "    def fit(self, X, y=None): return self\n",
        "    def transform(self, X): return X.drop(columns=[self.text_key])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uv4Klmhqncp8"
      },
      "outputs": [],
      "source": [
        "original_targets = ['Likes', 'RetweetCount', 'Reach']\n",
        "log_target = 'Reach_log'\n",
        "target_cols = ['Likes', 'RetweetCount', log_target]\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –¥–∞—Ç–∞—Å–µ—Ç\n",
        "df = df.dropna(subset=['text', 'Weekday', 'Hour'] + original_targets)\n",
        "df['Weekday'] = LabelEncoder().fit_transform(df['Weekday'])\n",
        "df['Reach_log'] = np.log1p(df['Reach'])\n",
        "df = extract_text_features(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6nkIQOYv7SJ"
      },
      "outputs": [],
      "source": [
        "categorical_features = ['Weekday']\n",
        "numerical_features = ['Hour', 'word_count', 'has_question', 'has_exclaim', 'has_emoji', 'has_hashtag', 'has_mention']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZef0rZJnd_p"
      },
      "outputs": [],
      "source": [
        "target_cols = ['Likes', 'RetweetCount', 'Reach']\n",
        "df = df.dropna(subset=['text_clean', 'Weekday', 'Hour'] + target_cols)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "df['Weekday'] = LabelEncoder().fit_transform(df['Weekday'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LawkBBqNnfj8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "df['Reach_log'] = np.log1p(df['Reach'])\n",
        "df['Likes_log'] = np.log1p(df['Likes'])\n",
        "df['Retweet_log'] = np.log1p(df['RetweetCount'])\n",
        "\n",
        "df['is_retweet'] = df['text'].str.lower().str.startswith('rt').astype(int)\n",
        "\n",
        "df['is_dead'] = (df['Likes'] == 0).astype(int)\n",
        "\n",
        "df['engagement_score_raw'] = (\n",
        "    0.6 * df['Likes_log'] +\n",
        "    0.2 * df['Retweet_log'] * (1 - df['is_retweet']) +\n",
        "    0.2 * df['Reach_log'] -\n",
        "    1.5 * df['is_dead'])\n",
        "\n",
        "scaler_minmax = MinMaxScaler(feature_range=(0, 10))\n",
        "df['engagement_score'] = scaler_minmax.fit_transform(df[['engagement_score_raw']])\n",
        "y=df['engagement_score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2etdKnQuIQhV"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGI0pY-CIS0S"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "class BertEmbedder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, model_name='bert-base-uncased'):\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "        self.model = BertModel.from_pretrained(model_name)\n",
        "        self.model.eval()\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = torch.device('cuda')\n",
        "        else:\n",
        "            self.device = torch.device('cpu')\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        embeddings = []\n",
        "        for text in X:\n",
        "            inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "            inputs = {key: value.to(self.device) for key, value in inputs.items()}  # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "            # –ò—Å–ø–æ–ª—å–∑—É–µ–º [CLS]-—Ç–æ–∫–µ–Ω –∫–∞–∫ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞\n",
        "            cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()  # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞ CPU\n",
        "            embeddings.append(cls_embedding)\n",
        "        return np.array(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcELwkBtnm2a"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import FunctionTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q094SJRkvw9C"
      },
      "outputs": [],
      "source": [
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numerical_features),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMNeO_bYvWuA"
      },
      "outputs": [],
      "source": [
        "\n",
        "full_pipeline = FeatureUnion([\n",
        "    ('text', Pipeline([\n",
        "        ('selector', TextSelector('text_clean')),\n",
        "        ('bert_embed', BertEmbedder())\n",
        "    ])),\n",
        "    ('meta', Pipeline([\n",
        "        ('drop_text', ColumnDropper('text_clean')),\n",
        "        ('preprocessor', preprocessor)\n",
        "    ]))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4wjJ1qVnoB-"
      },
      "outputs": [],
      "source": [
        "\n",
        "X = df[['text_clean', 'Weekday', 'Hour', 'word_count', 'has_question', 'has_exclaim', 'has_emoji', 'has_hashtag', 'has_mention']]\n",
        "y = df['engagement_score']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_trans = full_pipeline.fit_transform(X_train)\n",
        "X_test_trans = full_pipeline.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BFBjO2J6IHY"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.histplot(y, bins=50, kde=True)\n",
        "plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ engagement_score')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "av6Pkpn06qGp"
      },
      "outputs": [],
      "source": [
        "df.sort_values('engagement_score', ascending=False).head(10)[['text_clean', 'engagement_score','Likes', 'RetweetCount', 'Reach']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgLSeG1ynpaJ"
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_trans, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "lgbm = LGBMRegressor(\n",
        "    n_estimators=1200,\n",
        "    learning_rate=0.01,\n",
        "    num_leaves=128,\n",
        "    max_depth=10,\n",
        "    min_child_samples=10,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    reg_alpha=0.05,\n",
        "    reg_lambda=0.05,\n",
        "    random_state=42,\n",
        "    device='cpu'\n",
        ")\n",
        "lgbm.fit(X_train_split, y_train_split)\n",
        "\n",
        "y_pred = lgbm.predict(X_val_split)\n",
        "r2 = r2_score(y_val_split, y_pred)\n",
        "mae = mean_absolute_error(y_val_split, y_pred)\n",
        "\n",
        "print(f\"‚úÖ R¬≤: {r2:.4f}\")\n",
        "print(f\"üìâ MAE: {mae:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kvOPKcJtQC2"
      },
      "outputs": [],
      "source": [
        "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ\n",
        "lgbm.booster_.save_model(\"lgbm_model.txt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRkrbpZXtUdA"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "lgbm = lgb.Booster(model_file=\"lgbm_model.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ARouaR3aAL1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "y_pred = lgbm.predict(X_val_split)\n",
        "y_true = y_val_split\n",
        "\n",
        "y_pred = np.array(y_pred)\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "within_range = np.abs(y_pred - y_true) <= 1\n",
        "count_within_range = np.sum(within_range)\n",
        "total = len(y_true)\n",
        "percent_within_range = (count_within_range / total) * 100\n",
        "\n",
        "print(f\"‚úÖ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø–∞–¥–∞–Ω–∏–π –≤ ¬±1: {count_within_range}/{total} ({percent_within_range:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqafxNs0mKYo"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07DkH_pzl3ZA"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, DataCollatorForSeq2Seq\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "import json\n",
        "\n",
        "def load_jsonl_for_finetune(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = [json.loads(line) for line in f]\n",
        "    return Dataset.from_list([\n",
        "        {\n",
        "            \"input_text\": f\"\"\"Original tweet: \"{ex['original_tweet']}\"\\nSuggestions:\\n- {chr(10).join(ex['suggestions'])}\\n\\nRewrite the tweet to maximize engagement.\"\"\",\n",
        "            \"target_text\": ex[\"enhanced_tweet\"]\n",
        "        }\n",
        "        for ex in data\n",
        "    ])\n",
        "\n",
        "dataset = load_jsonl_for_finetune(\"/content/diverse_emojified_tweets_500.jsonl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6PHJ7jOGN5z"
      },
      "outputs": [],
      "source": [
        "model_name = \"google/flan-t5-large\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "emoji_list = [\"üî•\", \"üöÄ\", \"üéâ\", \"üì¢\", \"üëâ\", \"üòé\", \"üíº\", \"üìå\", \"üîî\", \"üß†\", \"üóìÔ∏è\", \"üìÖ\", \"üí°\", \"üë®‚Äçüíª\", \"‚ö°\", \"üåê\"]\n",
        "\n",
        "tokenizer.add_tokens(emoji_list)\n",
        "\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "def preprocess(example):\n",
        "    return tokenizer(example['input_text'], text_target=example['target_text'], truncation=True)\n",
        "tokenized = dataset.map(preprocess, batched=True)\n",
        "\n",
        "collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHzpN9ZNGd6M"
      },
      "outputs": [],
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./flan-t5-enhanced-tweet-model\",\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=5e-5,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_steps=10,\n",
        "    fp16=True,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized,\n",
        "    eval_dataset=tokenized,\n",
        "    data_collator=collator)\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "trainer.save_model(\"./flan-t5-enhanced-tweet-model\")\n",
        "tokenizer.save_pretrained(\"./flan-t5-enhanced-tweet-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojyS26Nfjimz"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_path = \"./flan-t5-enhanced-tweet-model\"\n",
        "\n",
        "generator = pipeline(\"text2text-generation\", model=model_path, tokenizer=model_path)\n",
        "def generate_enhanced_tweet(original_tweet, suggestions, model=generator):\n",
        "    prompt = f\"\"\"Original tweet: \"{original_tweet}\"\n",
        "\n",
        "Suggestions:\n",
        "- {chr(10).join(suggestions)}\n",
        "\n",
        "Rewrite the tweet to maximize engagement, keeping the original meaning, and including suggested enhancements like excitement, hashtags, and engagement features such as questions or emojis.\"\"\"\n",
        "    result = model(prompt, max_length=150, num_beams=5, do_sample=True, temperature=0.9)[0]['generated_text']\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wf-nWFxFntyZ"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "def suggest_enhancement(tweet_data, model=lgbm, pipeline=full_pipeline, step=3, text_model=generator):\n",
        "    tweet_df = pd.DataFrame([tweet_data])\n",
        "    transformed = pipeline.transform(tweet_df)\n",
        "    current_pred = model.predict(transformed)[0]\n",
        "\n",
        "    suggestions = []\n",
        "\n",
        "    #The best day and time\n",
        "    best_score = -np.inf\n",
        "    best_hour = None\n",
        "    best_day = None\n",
        "\n",
        "    weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "\n",
        "    for day in weekdays:\n",
        "        for hour in range(0, 24, step):\n",
        "            temp_data = copy.deepcopy(tweet_data)\n",
        "            temp_data['Weekday'] = day\n",
        "            temp_data['Hour'] = hour\n",
        "            temp_df = pd.DataFrame([temp_data])\n",
        "            transformed_temp = pipeline.transform(temp_df)\n",
        "            temp_score = model.predict(transformed_temp)[0]\n",
        "            if temp_score > best_score:\n",
        "                best_score = temp_score\n",
        "                best_hour = hour\n",
        "                best_day = day\n",
        "\n",
        "    if best_score > current_pred:\n",
        "        suggestions.append(\n",
        "            f\"üìÖ Consider posting on {best_day} around {best_hour}:00 ‚Äî model predicts higher engagement.\"\n",
        "        )\n",
        "\n",
        "    text = tweet_data['text']\n",
        "    if \"apply\" in text.lower():\n",
        "        suggestions.append(\"‚úÖ Try a more exciting tone'\")\n",
        "\n",
        "    if \"#\" not in text:\n",
        "        suggestions.append(\"‚úÖ Add relevant hashtags\")\n",
        "    elif tweet_data.get(\"has_hashtag\", 0) < 2:\n",
        "        suggestions.append(\"‚úÖ Use at least 2‚Äì3 hashtags.\")\n",
        "\n",
        "    if tweet_data.get(\"has_emoji\", 0) == 0:\n",
        "        suggestions.append(\"‚úÖ Add emojis to grab attention üéØüî•üíº\")\n",
        "    if tweet_data.get(\"has_exclaim\", 0) == 0:\n",
        "        suggestions.append(\"‚úÖ Use exclamation marks to boost excitement!\")\n",
        "    if tweet_data.get(\"has_question\", 0) == 0:\n",
        "        suggestions.append(\"‚úÖ Ask a question to engage your audience.\")\n",
        "\n",
        "    enhanced_text = None\n",
        "    if text_model:\n",
        "        prompt = f\"\"\"Original tweet: \"{text}\"\n",
        "\n",
        "Suggestions:\n",
        "- {chr(10).join(suggestions)}\n",
        "\n",
        "Now, please rewrite the tweet to make it more engaging and exciting!\n",
        "- Include emojis to grab attention\n",
        "- Add relevant hashtags\n",
        "- Use action verbs to create urgency and excitement\n",
        "- Try using exclamation marks to energize the tone\n",
        "- Consider adding a question to engage the audience\n",
        "\n",
        "Ensure the tweet remains true to the original message but make it more attractive and interactive!\"\"\"\n",
        "\n",
        "        enhanced_text = text_model(prompt, max_length=150, num_beams=5, do_sample=True, temperature=1.3)[0]['generated_text']\n",
        "\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"prompt\": prompt,\n",
        "        \"Predicted Engagement Score\": round(float(current_pred), 2),\n",
        "        \"Best Posting Time\": f\"{best_day} at {best_hour}:00\",\n",
        "        \"Best Score Estimate\": round(float(best_score), 2),\n",
        "        \"Suggested Enhancements\": suggestions,\n",
        "        \"Enhanced Tweet\": enhanced_text\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXdXVEpLb0MA"
      },
      "outputs": [],
      "source": [
        "example = {\n",
        "    \"text\": \"New job opening at our company! Apply here: https://vk.com #hiring #jobs\",\n",
        "    \"Sentiment\": \"Positive\",\n",
        "    \"Weekday\": \"Monday\",\n",
        "    \"Hour\": 18.0\n",
        "}\n",
        "sg=extract_text_features_from_json(example)\n",
        "print(sg)\n",
        "suggest_enhancement(sg[0],text_model=generator)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMEmkH0LgYGU"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNOqw7AF9VpyXzuha5pn319",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}